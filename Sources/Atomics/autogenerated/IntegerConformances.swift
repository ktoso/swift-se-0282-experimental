//===----------------------------------------------------------------------===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2020 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//

// #############################################################################
// #                                                                           #
// #            DO NOT EDIT THIS FILE; IT IS AUTOGENERATED.                    #
// #                                                                           #
// #############################################################################


import _AtomicsShims

extension Int: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = Int

    @usableFromInline
    var _storage: _AtomicIntStorage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_Int(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_Int(_storage)
    }
  }
}

extension Int.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicIntStorage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicIntStorage.self)
  }
}

extension Int.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_Int(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_Int(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_Int(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_Int(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_Int(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_Int(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_Int(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_Int(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_Int(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_Int(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_Int(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_Int(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_Int(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_Int(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_Int(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_Int(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_Int(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_Int(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_Int(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_Int(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_Int(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_Int(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_Int(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_Int(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_Int(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_Int(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_Int(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_Int(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_Int(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_Int(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_Int(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_Int(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_Int(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_Int(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_Int(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_Int(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_Int(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension Int64: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = Int64

    @usableFromInline
    var _storage: _AtomicInt64Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_Int64(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_Int64(_storage)
    }
  }
}

extension Int64.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicInt64Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicInt64Storage.self)
  }
}

extension Int64.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_Int64(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_Int64(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_Int64(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_Int64(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_Int64(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_Int64(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_Int64(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_Int64(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_Int64(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_Int64(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_Int64(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int64(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int64(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int64(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int64(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_Int64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int64(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_Int64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_Int64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_Int64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_Int64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_Int64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_Int64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_Int64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_Int64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_Int64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_Int64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_Int64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_Int64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_Int64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_Int64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_Int64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_Int64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_Int64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_Int64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_Int64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_Int64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_Int64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_Int64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_Int64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_Int64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_Int64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension Int32: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = Int32

    @usableFromInline
    var _storage: _AtomicInt32Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_Int32(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_Int32(_storage)
    }
  }
}

extension Int32.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicInt32Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicInt32Storage.self)
  }
}

extension Int32.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_Int32(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_Int32(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_Int32(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_Int32(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_Int32(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_Int32(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_Int32(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_Int32(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_Int32(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_Int32(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_Int32(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int32(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int32(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int32(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int32(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_Int32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int32(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_Int32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_Int32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_Int32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_Int32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_Int32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_Int32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_Int32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_Int32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_Int32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_Int32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_Int32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_Int32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_Int32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_Int32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_Int32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_Int32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_Int32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_Int32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_Int32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_Int32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_Int32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_Int32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_Int32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_Int32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_Int32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension Int16: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = Int16

    @usableFromInline
    var _storage: _AtomicInt16Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_Int16(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_Int16(_storage)
    }
  }
}

extension Int16.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicInt16Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicInt16Storage.self)
  }
}

extension Int16.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_Int16(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_Int16(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_Int16(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_Int16(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_Int16(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_Int16(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_Int16(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_Int16(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_Int16(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_Int16(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_Int16(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int16(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int16(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int16(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int16(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_Int16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int16(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_Int16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_Int16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_Int16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_Int16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_Int16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_Int16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_Int16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_Int16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_Int16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_Int16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_Int16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_Int16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_Int16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_Int16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_Int16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_Int16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_Int16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_Int16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_Int16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_Int16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_Int16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_Int16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_Int16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_Int16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_Int16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension Int8: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = Int8

    @usableFromInline
    var _storage: _AtomicInt8Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_Int8(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_Int8(_storage)
    }
  }
}

extension Int8.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicInt8Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicInt8Storage.self)
  }
}

extension Int8.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_Int8(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_Int8(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_Int8(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_Int8(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_Int8(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_Int8(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_Int8(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_Int8(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_Int8(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_Int8(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_Int8(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int8(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int8(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int8(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int8(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_Int8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_Int8(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_Int8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_Int8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_Int8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_Int8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_Int8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_Int8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_Int8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_Int8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_Int8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_Int8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_Int8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_Int8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_Int8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_Int8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_Int8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_Int8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_Int8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_Int8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_Int8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_Int8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_Int8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_Int8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_Int8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_Int8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_Int8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension UInt: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = UInt

    @usableFromInline
    var _storage: _AtomicUIntStorage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_UInt(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_UInt(_storage)
    }
  }
}

extension UInt.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicUIntStorage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicUIntStorage.self)
  }
}

extension UInt.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_UInt(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_UInt(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_UInt(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_UInt(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_UInt(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_UInt(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_UInt(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_UInt(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_UInt(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_UInt(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_UInt(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_UInt(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_UInt(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_UInt(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_UInt(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_UInt(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_UInt(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_UInt(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_UInt(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_UInt(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_UInt(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_UInt(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_UInt(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_UInt(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_UInt(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_UInt(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_UInt(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_UInt(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_UInt(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_UInt(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_UInt(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_UInt(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_UInt(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_UInt(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_UInt(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_UInt(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_UInt(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension UInt64: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = UInt64

    @usableFromInline
    var _storage: _AtomicUInt64Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_UInt64(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_UInt64(_storage)
    }
  }
}

extension UInt64.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicUInt64Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicUInt64Storage.self)
  }
}

extension UInt64.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_UInt64(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_UInt64(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_UInt64(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_UInt64(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_UInt64(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_UInt64(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_UInt64(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_UInt64(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_UInt64(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_UInt64(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_UInt64(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt64(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt64(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt64(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt64(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_UInt64(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt64(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_UInt64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_UInt64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_UInt64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_UInt64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_UInt64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_UInt64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_UInt64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_UInt64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_UInt64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_UInt64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_UInt64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_UInt64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_UInt64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_UInt64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_UInt64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_UInt64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_UInt64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_UInt64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_UInt64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_UInt64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_UInt64(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_UInt64(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_UInt64(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_UInt64(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_UInt64(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension UInt32: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = UInt32

    @usableFromInline
    var _storage: _AtomicUInt32Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_UInt32(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_UInt32(_storage)
    }
  }
}

extension UInt32.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicUInt32Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicUInt32Storage.self)
  }
}

extension UInt32.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_UInt32(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_UInt32(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_UInt32(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_UInt32(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_UInt32(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_UInt32(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_UInt32(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_UInt32(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_UInt32(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_UInt32(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_UInt32(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt32(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt32(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt32(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt32(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_UInt32(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt32(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_UInt32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_UInt32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_UInt32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_UInt32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_UInt32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_UInt32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_UInt32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_UInt32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_UInt32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_UInt32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_UInt32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_UInt32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_UInt32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_UInt32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_UInt32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_UInt32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_UInt32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_UInt32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_UInt32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_UInt32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_UInt32(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_UInt32(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_UInt32(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_UInt32(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_UInt32(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension UInt16: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = UInt16

    @usableFromInline
    var _storage: _AtomicUInt16Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_UInt16(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_UInt16(_storage)
    }
  }
}

extension UInt16.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicUInt16Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicUInt16Storage.self)
  }
}

extension UInt16.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_UInt16(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_UInt16(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_UInt16(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_UInt16(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_UInt16(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_UInt16(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_UInt16(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_UInt16(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_UInt16(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_UInt16(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_UInt16(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt16(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt16(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt16(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt16(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_UInt16(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt16(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_UInt16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_UInt16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_UInt16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_UInt16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_UInt16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_UInt16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_UInt16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_UInt16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_UInt16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_UInt16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_UInt16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_UInt16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_UInt16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_UInt16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_UInt16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_UInt16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_UInt16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_UInt16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_UInt16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_UInt16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_UInt16(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_UInt16(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_UInt16(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_UInt16(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_UInt16(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
extension UInt8: AtomicInteger {
  public struct AtomicRepresentation {
    public typealias Value = UInt8

    @usableFromInline
    var _storage: _AtomicUInt8Storage

    @inline(__always) @_alwaysEmitIntoClient
    public init(_ value: Value) {
      self._storage = _sa_prepare_UInt8(value)
    }

    @inline(__always) @_alwaysEmitIntoClient
    public func dispose() -> Value {
      _sa_dispose_UInt8(_storage)
    }
  }
}

extension UInt8.AtomicRepresentation {
  @_transparent @_alwaysEmitIntoClient
  @usableFromInline
  static func _extract(
    _ ptr: UnsafeMutablePointer<Self>
  ) -> UnsafeMutablePointer<_AtomicUInt8Storage> {
    // `Self` is layout-compatible with its only stored property.
    return UnsafeMutableRawPointer(ptr)
      .assumingMemoryBound(to: _AtomicUInt8Storage.self)
  }
}

extension UInt8.AtomicRepresentation: AtomicIntegerStorage {
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicLoad(
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicLoadOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_load_relaxed_UInt8(_extract(pointer))
    case .acquiring:
      return _sa_load_acquire_UInt8(_extract(pointer))
    case .sequentiallyConsistent:
      return _sa_load_seq_cst_UInt8(_extract(pointer))
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicStore(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicStoreOrdering
  ) {
    switch ordering {
    case .relaxed:
      _sa_store_relaxed_UInt8(_extract(pointer), desired)
    case .releasing:
      _sa_store_release_UInt8(_extract(pointer), desired)
    case .sequentiallyConsistent:
      _sa_store_seq_cst_UInt8(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicExchange(
    _ desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_exchange_relaxed_UInt8(_extract(pointer), desired)
    case .acquiring:
      return _sa_exchange_acquire_UInt8(_extract(pointer), desired)
    case .releasing:
      return _sa_exchange_release_UInt8(_extract(pointer), desired)
    case .acquiringAndReleasing:
      return _sa_exchange_acq_rel_UInt8(_extract(pointer), desired)
    case .sequentiallyConsistent:
      return _sa_exchange_seq_cst_UInt8(_extract(pointer), desired)
    default:
      fatalError("Unsupported ordering")
    }
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    switch ordering {
    case .relaxed:
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt8(
        _extract(pointer),
        &expected, desired)
    case .acquiring:
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt8(
        _extract(pointer),
        &expected, desired)
    case .releasing:
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt8(
        _extract(pointer),
        &expected, desired)
    case .acquiringAndReleasing:
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt8(
        _extract(pointer),
        &expected, desired)
    case .sequentiallyConsistent:
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected, desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_strong_relaxed_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_strong_acquire_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_strong_acquire_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_release_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_strong_acq_rel_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_strong_acq_rel_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_strong_seq_cst_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_strong_seq_cst_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_strong_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  public static func atomicWeakCompareExchange(
    expected: Value,
    desired: Value,
    at pointer: UnsafeMutablePointer<Self>,
    successOrdering: AtomicUpdateOrdering,
    failureOrdering: AtomicLoadOrdering
  ) -> (exchanged: Bool, original: Value) {
    var expected = expected
    let exchanged: Bool
    // FIXME: stdatomic.h (and LLVM underneath) doesn't support
    // arbitrary ordering combinations yet, so upgrade the success
    // ordering when necessary so that it is at least as "strong" as
    // the failure case.
    switch (successOrdering, failureOrdering) {
    case (.relaxed, .relaxed):
      exchanged = _sa_cmpxchg_weak_relaxed_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.relaxed, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .relaxed):
      exchanged = _sa_cmpxchg_weak_acquire_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .acquiring):
      exchanged = _sa_cmpxchg_weak_acquire_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiring, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_release_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.releasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .relaxed):
      exchanged = _sa_cmpxchg_weak_acq_rel_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .acquiring):
      exchanged = _sa_cmpxchg_weak_acq_rel_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.acquiringAndReleasing, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .relaxed):
      exchanged = _sa_cmpxchg_weak_seq_cst_relaxed_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .acquiring):
      exchanged = _sa_cmpxchg_weak_seq_cst_acquire_UInt8(
        _extract(pointer),
        &expected,
        desired)
    case (.sequentiallyConsistent, .sequentiallyConsistent):
      exchanged = _sa_cmpxchg_weak_seq_cst_seq_cst_UInt8(
        _extract(pointer),
        &expected,
        desired)
    default:
      fatalError("Unsupported ordering")
    }
    return (exchanged, expected)
  }

  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingIncrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_add_relaxed_UInt8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_add_acquire_UInt8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_add_release_UInt8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_add_acq_rel_UInt8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_add_seq_cst_UInt8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenWrappingDecrement(
    by operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_sub_relaxed_UInt8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_sub_acquire_UInt8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_sub_release_UInt8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_sub_acq_rel_UInt8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_sub_seq_cst_UInt8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseAnd(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_and_relaxed_UInt8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_and_acquire_UInt8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_and_release_UInt8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_and_acq_rel_UInt8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_and_seq_cst_UInt8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseOr(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_or_relaxed_UInt8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_or_acquire_UInt8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_or_release_UInt8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_or_acq_rel_UInt8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_or_seq_cst_UInt8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
  @_semantics("atomics.requires_constant_orderings")
  @_transparent @_alwaysEmitIntoClient
  @discardableResult
  public static func atomicLoadThenBitwiseXor(
    with operand: Value = 1,
    at pointer: UnsafeMutablePointer<Self>,
    ordering: AtomicUpdateOrdering
  ) -> Value {
    switch ordering {
    case .relaxed:
      return _sa_fetch_xor_relaxed_UInt8(
        _extract(pointer),
        operand)
    case .acquiring:
      return _sa_fetch_xor_acquire_UInt8(
        _extract(pointer),
        operand)
    case .releasing:
      return _sa_fetch_xor_release_UInt8(
        _extract(pointer),
        operand)
    case .acquiringAndReleasing:
      return _sa_fetch_xor_acq_rel_UInt8(
        _extract(pointer),
        operand)
    case .sequentiallyConsistent:
      return _sa_fetch_xor_seq_cst_UInt8(
        _extract(pointer),
        operand)
    default:
      fatalError("Unsupported ordering")
    }
  }
}
